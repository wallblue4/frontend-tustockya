# backend/app/main.py (versi√≥n optimizada para Render)
import os
import logging
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from .yolo_classifier import YOLOClassifier

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="üéæ Tennis Classifier API",
    description="Demo API para clasificaci√≥n de tenis con YOLO",
    version="1.0.0",
    docs_url="/docs",  # Swagger disponible en /docs
    redoc_url="/redoc"
)

# CORS permisivo para demo (ajustar en producci√≥n)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Cambiar por dominios espec√≠ficos en producci√≥n
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

# Variable global para el modelo
model = None

@app.on_event("startup")
async def startup_event():
    """Cargar modelo al iniciar"""
    global model
    try:
        model_path = os.getenv("MODEL_PATH", "models/best.pt")
        logger.info(f"üîÑ Cargando modelo desde: {model_path}")
        
        model = YOLOClassifier(model_path=model_path)
        logger.info("‚úÖ Modelo cargado exitosamente")
        
    except Exception as e:
        logger.error(f"‚ùå Error al cargar modelo: {e}")
        # No fallar el startup para que el health check funcione

@app.get("/")
async def root():
    """Endpoint ra√≠z con informaci√≥n del servicio"""
    return {
        "service": "Tennis Classifier API",
        "status": "running",
        "version": "1.0.0",
        "model_loaded": model is not None,
        "endpoints": {
            "classify": "POST /classify",
            "health": "GET /health", 
            "docs": "GET /docs"
        }
    }

@app.post("/classify")
async def classify_image(file: UploadFile = File(...)):
    """Clasificar imagen de tenis"""
    
    # Verificar modelo
    if not model:
        raise HTTPException(
            status_code=503, 
            detail="Modelo no disponible. El servicio se est√° inicializando."
        )
    
    # Validar archivo
    if not file.content_type or not file.content_type.startswith("image/"):
        raise HTTPException(
            status_code=400,
            detail="El archivo debe ser una imagen (jpg, png, etc.)"
        )
    
    # Limitar tama√±o (importante para tier gratuito)
    max_size = 5 * 1024 * 1024  # 5MB
    if hasattr(file, 'size') and file.size and file.size > max_size:
        raise HTTPException(
            status_code=413,
            detail="Imagen muy grande. M√°ximo 5MB permitido."
        )
    
    try:
        # Procesar imagen
        logger.info(f"üîÑ Procesando: {file.filename}")
        image_bytes = await file.read()
        
        # Predicci√≥n
        prediction = model.predict(image_bytes)
        
        logger.info(f"‚úÖ Predicci√≥n completada para: {file.filename}")
        
        return JSONResponse(content={
            "success": True,
            "filename": file.filename,
            "prediction": prediction,
            "message": "Clasificaci√≥n completada exitosamente"
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error en predicci√≥n: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error procesando imagen: {str(e)}"
        )

@app.get("/health")
async def health_check():
    """Health check para monitoreo"""
    return {
        "status": "healthy" if model else "starting",
        "model_loaded": model is not None,
        "service": "tennis-classifier-api",
        "timestamp": os.getenv("RENDER_SERVICE")  # Variable de Render
    }

# Endpoint adicional para debug (solo en desarrollo)
@app.get("/debug")
async def debug_info():
    """Informaci√≥n de debug"""
    import psutil
    
    return {
        "environment": os.getenv("ENVIRONMENT", "unknown"),
        "model_path": os.getenv("MODEL_PATH", "unknown"),
        "memory_usage": f"{psutil.virtual_memory().percent:.1f}%",
        "model_status": "loaded" if model else "not_loaded"
    }
